{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is for a job application at Interana. This little quiz acompanied the application. I'm documenting my thought process here.\n",
      "\n",
      "#The question"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Please use the data from here:\n",
      "\n",
      "http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.geojson\n",
      "\n",
      "to show us the highest magnitude earthquake within the last 7 days within 100 miles of our office.\n",
      "\n",
      "Tell us how you chose your solution.\n",
      "\n",
      "Please remember that the purpose of the task is less about the answer and more about how you got there. In the field, you'll be left to your devices to use any combination of tools you like to solve this and get the data being asked. For this part of the problem, please do it in two ways:\u00a0\n",
      "\n",
      "1) Choose any combination of technologies and tools to answer the question. Please be very detailed in your thought process, selection criteria, and any pertinent steps you take to get there. There are no wrong answers! In the field it's always about \"getting it done\".\n",
      "\n",
      "2) Please repeat the exercise, but focus on using UNIX command line tools. You should be using Linux and ideally python or bash scripting to locate the records.\u00a0\n",
      "\n",
      "Once 1 and 2 are completed, discuss how you would convert the JSON data to CSV and what the best way to do that would be. Provide as much detail about the decision as possible."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The Process\n",
      "\n",
      "Python is my go-to tool for many tasks and quick programs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets load the data\n",
      "import requests\n",
      "geojson = requests.get(\"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.geojson\").content"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "hm.. looks like geojason.\n",
      "\n",
      "        pip install geojsonio"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import geojsonio\n",
      "#geojsonio.embed(geojson)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Oh look, it seems like there is to much data to easily visualize. The above is commented out for crashing my browser. This is going to be fun :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So here is what the the data looks like "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from json import loads, dumps\n",
      "doc = loads(geojson)\n",
      "doc['features'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "{u'geometry': {u'coordinates': [7.6454, 77.3918, 10], u'type': u'Point'},\n",
        " u'id': u'usc000tenj',\n",
        " u'properties': {u'alert': None,\n",
        "  u'cdi': 1,\n",
        "  u'code': u'c000tenj',\n",
        "  u'detail': u'http://earthquake.usgs.gov/earthquakes/feed/v1.0/detail/usc000tenj.geojson',\n",
        "  u'dmin': 1.77,\n",
        "  u'felt': 0,\n",
        "  u'gap': 82,\n",
        "  u'ids': u',usc000tenj,',\n",
        "  u'mag': 5.4,\n",
        "  u'magType': u'mb',\n",
        "  u'mmi': None,\n",
        "  u'net': u'us',\n",
        "  u'nst': None,\n",
        "  u'place': u'209km WSW of Longyearbyen, Svalbard and Jan Mayen',\n",
        "  u'rms': 0.68,\n",
        "  u'sig': 449,\n",
        "  u'sources': u',us,',\n",
        "  u'status': u'reviewed',\n",
        "  u'time': 1421008473050,\n",
        "  u'title': u'M 5.4 - 209km WSW of Longyearbyen, Svalbard and Jan Mayen',\n",
        "  u'tsunami': None,\n",
        "  u'type': u'earthquake',\n",
        "  u'types': u',cap,dyfi,geoserve,nearby-cities,origin,phase-data,',\n",
        "  u'tz': 60,\n",
        "  u'updated': 1421009541096,\n",
        "  u'url': u'http://earthquake.usgs.gov/earthquakes/eventpage/usc000tenj'},\n",
        " u'type': u'Feature'}"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's find the closest one to Interana. A quick search yields their adress. 68 Willow Rd Menlo Park, CA 94025, or (37.452241, -122.167082). Let's make a filter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from geopy.distance import VincentyDistance as vd\n",
      "from geopy.point import Point\n",
      "\n",
      "# interana = Point(37.452241, -122.167082)\n",
      "# it seems like the USGS uses (longitude, latitude) pairs\n",
      "interana = Point(-122.167082, 37.452241)\n",
      "\n",
      "max_dist = 100\n",
      "def distance_filter(event):\n",
      "    return vd(interana, event.point()).miles < max_dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And a class to encapsulate and add methods to the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "\n",
      "now = time() # in seconds since 1/1/1970\n",
      "seconds_in_day = 60*60*24\n",
      "\n",
      "class Event(dict):\n",
      "    def mag(self):\n",
      "        return float(self['properties']['mag'])\n",
      "\n",
      "    def days_ago(self):\n",
      "        return (now - float(self['properties']['time'])/1000) / seconds_in_day\n",
      "\n",
      "    def point(self):\n",
      "        return Point(self['geometry']['coordinates'])\n",
      "        \n",
      "    def to_json(self):\n",
      "        return dumps(self)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# And the answer is..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "events = map(Event, doc['features'])\n",
      "recent = filter(lambda e: e.days_ago() <= 7, events)\n",
      "near = filter(distance_filter, recent)\n",
      "max(near, key=lambda e: e.mag())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "{u'geometry': {u'coordinates': [-122.1376648, 39.3945007, 26.37],\n",
        "  u'type': u'Point'},\n",
        " u'id': u'nc72378716',\n",
        " u'properties': {u'alert': None,\n",
        "  u'cdi': 2.2,\n",
        "  u'code': u'72378716',\n",
        "  u'detail': u'http://earthquake.usgs.gov/earthquakes/feed/v1.0/detail/nc72378716.geojson',\n",
        "  u'dmin': 0.1354,\n",
        "  u'felt': 6,\n",
        "  u'gap': 39,\n",
        "  u'ids': u',nc72378716,',\n",
        "  u'mag': 3,\n",
        "  u'magType': u'md',\n",
        "  u'mmi': None,\n",
        "  u'net': u'nc',\n",
        "  u'nst': 41,\n",
        "  u'place': u'13km NNE of Maxwell, California',\n",
        "  u'rms': 0.33,\n",
        "  u'sig': 140,\n",
        "  u'sources': u',nc,',\n",
        "  u'status': u'automatic',\n",
        "  u'time': 1420897506930,\n",
        "  u'title': u'M 3.0 - 13km NNE of Maxwell, California',\n",
        "  u'tsunami': None,\n",
        "  u'type': u'earthquake',\n",
        "  u'types': u',dyfi,focal-mechanism,general-link,geoserve,nearby-cities,origin,phase-data,scitech-link,',\n",
        "  u'tz': -480,\n",
        "  u'updated': 1420941801726,\n",
        "  u'url': u'http://earthquake.usgs.gov/earthquakes/eventpage/nc72378716'},\n",
        " u'type': u'Feature'}"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 2\n",
      "> Please repeat the exercise, but focus on using UNIX command line tools. You should be using Linux and ideally python or bash scripting to locate the records. \n",
      "\n",
      "It's a good thing ipython makes it easy to use the command line with python. Let's begin with curl."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.geojson > quakes.geojson"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 50784    0 50784    0     0  55412      0 --:--:-- --:--:-- --:--:-- 55380"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  110k    0  110k    0     0  59550      0 --:--:--  0:00:01 --:--:-- 59538"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  166k    0  166k    0     0  58155      0 --:--:--  0:00:02 --:--:-- 58144"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  219k    0  219k    0     0  57359      0 --:--:--  0:00:03 --:--:-- 57355"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  280k    0  280k    0     0  58417      0 --:--:--  0:00:04 --:--:-- 58411"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  341k    0  341k    0     0  59096      0 --:--:--  0:00:05 --:--:-- 59778"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  400k    0  400k    0     0  59315      0 --:--:--  0:00:06 --:--:-- 59235"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  455k    0  455k    0     0  59011      0 --:--:--  0:00:07 --:--:-- 59506"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  515k    0  515k    0     0  59168      0 --:--:--  0:00:08 --:--:-- 60583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  565k    0  565k    0     0  58307      0 --:--:--  0:00:09 --:--:-- 58206"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  612k    0  612k    0     0  57512      0 --:--:--  0:00:10 --:--:-- 55619"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  669k    0  669k    0     0  57590      0 --:--:--  0:00:11 --:--:-- 55202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  721k    0  721k    0     0  57112      0 --:--:--  0:00:12 --:--:-- 54120"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  772k    0  772k    0     0  56680      0 --:--:--  0:00:13 --:--:-- 52262"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  825k    0  825k    0     0  56618      0 --:--:--  0:00:14 --:--:-- 53253"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  873k    0  873k    0     0  56242      0 --:--:--  0:00:15 --:--:-- 53469"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  927k    0  927k    0     0  56157      0 --:--:--  0:00:16 --:--:-- 52760"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  981k    0  981k    0     0  55955      0 --:--:--  0:00:17 --:--:-- 52994"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1036k    0 1036k    0     0  56077      0 --:--:--  0:00:18 --:--:-- 54380"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1074k    0 1074k    0     0  55226      0 --:--:--  0:00:19 --:--:-- 51072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1124k    0 1124k    0     0  55070      0 --:--:--  0:00:20 --:--:-- 51346"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1174k    0 1174k    0     0  54855      0 --:--:--  0:00:21 --:--:-- 50458"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1231k    0 1231k    0     0  54958      0 --:--:--  0:00:22 --:--:-- 51349"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1281k    0 1281k    0     0  54849      0 --:--:--  0:00:23 --:--:-- 50209"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1355k    0 1355k    0     0  55717      0 --:--:--  0:00:24 --:--:-- 57678"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1443k    0 1443k    0     0  57022      0 --:--:--  0:00:25 --:--:-- 65163"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1549k    0 1549k    0     0  58965      0 --:--:--  0:00:26 --:--:-- 77048"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1661k    0 1661k    0     0  60975      0 --:--:--  0:00:27 --:--:-- 88760"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1775k    0 1775k    0     0  62885      0 --:--:--  0:00:28 --:--:--   98k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1864k    0 1864k    0     0  63833      0 --:--:--  0:00:29 --:--:--  101k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1935k    0 1935k    0     0  64118      0 --:--:--  0:00:30 --:--:--   98k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 1981k    0 1981k    0     0  63569      0 --:--:--  0:00:31 --:--:-- 88305"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2031k    0 2031k    0     0  63182      0 --:--:--  0:00:32 --:--:-- 75495"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2072k    0 2072k    0     0  62500      0 --:--:--  0:00:33 --:--:-- 60294"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2105k    0 2105k    0     0  61761      0 --:--:--  0:00:34 --:--:-- 49350"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2148k    0 2148k    0     0  61227      0 --:--:--  0:00:35 --:--:-- 43399"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2196k    0 2196k    0     0  60943      0 --:--:--  0:00:36 --:--:-- 44149"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2257k    0 2257k    0     0  60979      0 --:--:--  0:00:37 --:--:-- 46457"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2306k    0 2306k    0     0  60532      0 --:--:--  0:00:39 --:--:-- 47331"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2347k    0 2347k    0     0  60105      0 --:--:--  0:00:39 --:--:-- 48757"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2407k    0 2407k    0     0  60254      0 --:--:--  0:00:40 --:--:-- 53243"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2481k    0 2481k    0     0  60603      0 --:--:--  0:00:41 --:--:-- 58111"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 2580k    0 2580k    0     0  61557      0 --:--:--  0:00:42 --:--:-- 65945"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 3182k    0 3182k    0     0  74233      0 --:--:--  0:00:43 --:--:--  179k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 3985k    0 3985k    0     0  90885      0 --:--:--  0:00:44 --:--:--  333k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 4806k    0 4806k    0     0   104k      0 --:--:--  0:00:45 --:--:--  480k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 5509k    0 5509k    0     0   117k      0 --:--:--  0:00:46 --:--:--  607k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 5643k    0 5643k    0     0   119k      0 --:--:--  0:00:47 --:--:--  709k\r\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we can use this tool to navigate json http://trentm.com/json and search it\n",
      "\n",
      "    npm install json -g"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat quakes.geojson | json features | head -n 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\r\n",
        "  {\r\n",
        "    \"type\": \"Feature\",\r\n",
        "    \"properties\": {\r\n",
        "      \"mag\": 5.4,\r\n",
        "      \"place\": \"209km WSW of Longyearbyen, Svalbard and Jan Mayen\",\r\n",
        "      \"time\": 1421008473050,\r\n",
        "      \"updated\": 1421009541096,\r\n",
        "      \"tz\": 60,\r\n",
        "      \"url\": \"http://earthquake.usgs.gov/earthquakes/eventpage/usc000tenj\",\r\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seven_days_ago = now - 60*60*24*7*1000 # in ms\n",
      "!cat quakes.geojson | json features | json -c 'this.properties.time >= $seven_days_ago' | head -n 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\r\n",
        "  {\r\n",
        "    \"type\": \"Feature\",\r\n",
        "    \"properties\": {\r\n",
        "      \"mag\": 5.4,\r\n",
        "      \"place\": \"209km WSW of Longyearbyen, Svalbard and Jan Mayen\",\r\n",
        "      \"time\": 1421008473050,\r\n",
        "      \"updated\": 1421009541096,\r\n",
        "      \"tz\": 60,\r\n",
        "      \"url\": \"http://earthquake.usgs.gov/earthquakes/eventpage/usc000tenj\",\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is as far as the command line can take us. Let's drop back into pure python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recent_events = !cat quakes.geojson | json features | json -c 'this.properties.time >= $seven_days_ago'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "winner=max(filter(distance_filter, map(Event, loads(\"\".join(recent_events.list)))), key=lambda e: e.mag())\n",
      "print winner['properties']['title']\n",
      "geojsonio.embed(winner.to_json())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "M 3.0 - 13km NNE of Maxwell, California\n"
       ]
      },
      {
       "html": [
        "<iframe src=http://geojson.io/#data=data:application/json,%7B%22geometry%22%3A%20%7B%22type%22%3A%20%22Point%22%2C%20%22coordinates%22%3A%20%5B-122.1376648%2C%2039.3945007%2C%2026.37%5D%7D%2C%20%22type%22%3A%20%22Feature%22%2C%20%22properties%22%3A%20%7B%22rms%22%3A%200.33%2C%20%22code%22%3A%20%2272378716%22%2C%20%22cdi%22%3A%202.2%2C%20%22sources%22%3A%20%22%2Cnc%2C%22%2C%20%22nst%22%3A%2041%2C%20%22tz%22%3A%20-480%2C%20%22title%22%3A%20%22M%203.0%20-%2013km%20NNE%20of%20Maxwell%2C%20California%22%2C%20%22magType%22%3A%20%22md%22%2C%20%22detail%22%3A%20%22http%3A//earthquake.usgs.gov/earthquakes/feed/v1.0/detail/nc72378716.geojson%22%2C%20%22sig%22%3A%20140%2C%20%22net%22%3A%20%22nc%22%2C%20%22type%22%3A%20%22earthquake%22%2C%20%22status%22%3A%20%22automatic%22%2C%20%22updated%22%3A%201420941801726%2C%20%22felt%22%3A%206%2C%20%22alert%22%3A%20null%2C%20%22dmin%22%3A%200.1354%2C%20%22mag%22%3A%203%2C%20%22gap%22%3A%2039%2C%20%22types%22%3A%20%22%2Cdyfi%2Cfocal-mechanism%2Cgeneral-link%2Cgeoserve%2Cnearby-cities%2Corigin%2Cphase-data%2Cscitech-link%2C%22%2C%20%22url%22%3A%20%22http%3A//earthquake.usgs.gov/earthquakes/eventpage/nc72378716%22%2C%20%22ids%22%3A%20%22%2Cnc72378716%2C%22%2C%20%22tsunami%22%3A%20null%2C%20%22place%22%3A%20%2213km%20NNE%20of%20Maxwell%2C%20California%22%2C%20%22time%22%3A%201420897506930%2C%20%22mmi%22%3A%20null%7D%2C%20%22id%22%3A%20%22nc72378716%22%7D width=100% height=512></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "<IPython.core.display.HTML at 0x7f5f28924f10>"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Once 1 and 2 are completed, discuss how you would convert the JSON data to CSV and what the best way to do that would be. Provide as much detail about the decision as possible.\n",
      "\n",
      "I would use json2csv from the command line because it is simple. I prefer simple solutions.\n",
      "\n",
      "If I wanted more control over the encoding, I would use python's csv module, which has a class to easily encode dicts. This would be a good solution because I could easily modify it for reuse. I would use something like the following."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "def flatten(event):\n",
      "    d = {\"id\": event['id']}\n",
      "    d.update(event['geometry'])\n",
      "    d.update(event['properties'])\n",
      "    return d\n",
      "\n",
      "with open('quakes.csv', 'w') as csvf:\n",
      "    writer = csv.DictWriter(csvf, fieldnames=flatten(events[0]).keys())\n",
      "    writer.writeheader()\n",
      "    for event in events:\n",
      "        writer.writerow(flatten(events[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}